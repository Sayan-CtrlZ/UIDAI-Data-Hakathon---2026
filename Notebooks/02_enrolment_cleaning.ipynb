{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": "import pandas as pd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "656bc1df7b0ff8f5",
   "metadata": {},
   "source": [
    "enrolment_df = pd.read_csv(\"../data/processed/interim/enrolment_raw_merged.csv\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e16e2b8fdb46a00c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6be81b2537a7f0b4",
   "metadata": {},
   "source": [
    "enrolment_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f82068e508ceb89e",
   "metadata": {},
   "source": [
    "enrolment_df.columns"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eee584a0067ec741",
   "metadata": {},
   "source": "enrolment_df = enrolment_df.rename(columns={\"age_18_greater\": \"age_17_plus\"})",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3c1a445001ec21f3",
   "metadata": {},
   "source": [
    "enrolment_df[\"state\"] = enrolment_df[\"state\"].str.strip().str.title()\n",
    "enrolment_df[\"district\"] = enrolment_df[\"district\"].str.strip().str.title()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ae1cfa3e1ffb53ba",
   "metadata": {},
   "source": [
    "enrolment_df.isnull().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e6f239ca1523af7a",
   "metadata": {},
   "source": [
    "enrolment_df.shape\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a35bb59325eda791",
   "metadata": {},
   "source": [
    "enrolment_df = enrolment_df.drop_duplicates()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cc61114c6807a319",
   "metadata": {},
   "source": [
    "enrolment_df[\"date\"] = pd.to_datetime(enrolment_df[\"date\"], dayfirst=True)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8f87be917187b698",
   "metadata": {},
   "source": [
    "enrolment_df.dtypes"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6ba69aca47366d10",
   "metadata": {},
   "source": [
    "enrolment_df.shape\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "65f19b4a94348976",
   "metadata": {},
   "source": [
    "enrolment_df[enrolment_df[\"district\"] == \"100000\"]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "baea34fbf20a672a",
   "metadata": {},
   "source": [
    "enrolment_df[enrolment_df[\"district\"] == \"100000\"].shape[0]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f45d876a61781872",
   "metadata": {},
   "source": [
    "enrolment_df[enrolment_df[\"state\"] == \"100000\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7da45797b83c5e1b",
   "metadata": {},
   "source": [
    "enrolment_df[enrolment_df[\"state\"] == \"100000\"].shape[0]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1e8c37cf7a66d133",
   "metadata": {},
   "source": [
    "enrolment_df = enrolment_df[\n",
    "    ~(\n",
    "        enrolment_df[\"district\"].isin([\"100000\", 100000]) |\n",
    "        enrolment_df[\"state\"].isin([\"100000\", 100000])\n",
    "    )\n",
    "]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6fae67945686747b",
   "metadata": {},
   "source": [
    "enrolment_df.shape\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9fdc197a48f1d22f",
   "metadata": {},
   "source": [
    "enrolment_df[\"state\"].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5f62e2a14581924b",
   "metadata": {},
   "source": [
    "enrolment_state_mapping = {\n",
    "    \"Orissa\": \"Odisha\",\n",
    "    \"Jammu & Kashmir\": \"Jammu And Kashmir\",\n",
    "    \"Pondicherry\": \"Puducherry\",\n",
    "\n",
    "    \"West  Bengal\": \"West Bengal\",\n",
    "    \"West Bangal\": \"West Bengal\",\n",
    "    \"Westbengal\": \"West Bengal\",\n",
    "\n",
    "    \"Dadra And Nagar Haveli\": \"Dadra And Nagar Haveli And Daman And Diu\",\n",
    "    \"Dadra & Nagar Haveli\": \"Dadra And Nagar Haveli And Daman And Diu\",\n",
    "    \"Daman And Diu\": \"Dadra And Nagar Haveli And Daman And Diu\",\n",
    "    \"Daman & Diu\": \"Dadra And Nagar Haveli And Daman And Diu\",\n",
    "    \"The Dadra And Nagar Haveli And Daman And Diu\": \"Dadra And Nagar Haveli And Daman And Diu\",\n",
    "\n",
    "    \"Andaman & Nicobar Islands\": \"Andaman And Nicobar Islands\"\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------\n",
    "# Fix Hyderabad â†’ Telangana\n",
    "# -----------------------------\n",
    "\n",
    "mask = (\n",
    "    enrolment_df[\"district\"].astype(str).str.strip().str.title() == \"Hyderabad\"\n",
    ")\n",
    "\n",
    "affected_rows = mask.sum()\n",
    "\n",
    "enrolment_df.loc[mask, \"state\"] = \"Telangana\"\n",
    "\n",
    "print(f\"âœ” Hyderabad correction applied to {affected_rows} rows\")\n"
   ],
   "id": "a5699fd101a9e224",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------\n",
    "# Fix Adilabad â†’ Telangana\n",
    "# -----------------------------\n",
    "\n",
    "mask = (\n",
    "    enrolment_df[\"district\"].astype(str).str.strip().str.title() == \"Adilabad\"\n",
    ")\n",
    "\n",
    "affected_rows = mask.sum()\n",
    "\n",
    "enrolment_df.loc[mask, \"state\"] = \"Telangana\"\n",
    "\n",
    "print(f\"âœ” Hyderabad correction applied to {affected_rows} rows\")\n"
   ],
   "id": "8ab5ecf90f1ebb31",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8074b41f06168b0a",
   "metadata": {},
   "source": [
    "enrolment_df[\"state\"] = enrolment_df[\"state\"].replace(enrolment_state_mapping)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# normalize state & district names\n",
    "enrolment_df[\"state_clean\"] = (\n",
    "    enrolment_df[\"state\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    ")\n",
    "\n",
    "enrolment_df[\"district_clean\"] = (\n",
    "    enrolment_df[\"district\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    ")\n",
    "\n"
   ],
   "id": "99e074d8a5d4d59c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "before = len(enrolment_df)\n",
    "\n",
    "enrolment_df = enrolment_df[\n",
    "    (enrolment_df[\"state\"] != \"<unset>\") &\n",
    "    (enrolment_df[\"district\"] != \"<unset>\") &\n",
    "    (enrolment_df[\"pincode\"] != \"<unset>\")\n",
    "]\n",
    "\n",
    "after = len(enrolment_df)\n",
    "\n",
    "print(f\"Removed {before - after} rows with <unset> in key columns\")\n"
   ],
   "id": "830c7b25e560e9f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "40630b8a8e2173a6",
   "metadata": {},
   "source": [
    "enrolment_df[\"state\"].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d361258390bd97f4",
   "metadata": {},
   "source": [
    "enrolment_df.to_csv(\n",
    "    \"../data/processed/cleaned/enrolment_clean.csv\",\n",
    "    index=False\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# import pandas as pd\n",
    "# import nbformat\n",
    "# from nbformat.v4 import new_notebook, new_markdown_cell, new_code_cell\n",
    "# from pathlib import Path\n",
    "#\n",
    "# # =====================================================\n",
    "# # Paths\n",
    "# # =====================================================\n",
    "# CLEAN_DIR = Path(\"../data/processed/cleaned\")\n",
    "# NOTEBOOK_DIR = Path(\"../Notebooks/state_wise_cleaning\")\n",
    "# REFERENCE_DIR = Path(\"../data/processed/reference\")\n",
    "#\n",
    "# NOTEBOOK_DIR.mkdir(parents=True, exist_ok=True)\n",
    "# REFERENCE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "#\n",
    "# # =====================================================\n",
    "# # Load enrolment data to get states (source of truth)\n",
    "# # =====================================================\n",
    "# enrol_df = pd.read_csv(CLEAN_DIR / \"enrolment_clean.csv\")\n",
    "#\n",
    "# enrol_df[\"state\"] = enrol_df[\"state\"].astype(str).str.strip().str.title()\n",
    "# enrol_df[\"district\"] = enrol_df[\"district\"].astype(str).str.strip().str.title()\n",
    "#\n",
    "# states = sorted(enrol_df[\"state\"].dropna().unique())\n",
    "#\n",
    "# print(f\"Creating notebooks for {len(states)} states\")\n",
    "#\n",
    "#\n",
    "# # =====================================================\n",
    "# # Notebook template generation\n",
    "# # =====================================================\n",
    "# for state in states:\n",
    "#     safe_state = state.replace(\" \", \"_\")\n",
    "#     nb_path = NOTEBOOK_DIR / f\"{safe_state}_district_cleaning.ipynb\"\n",
    "#\n",
    "#     nb = new_notebook(cells=[\n",
    "#\n",
    "#         # ----------------------------\n",
    "#         # Markdown intro\n",
    "#         # ----------------------------\n",
    "#         new_markdown_cell(\n",
    "#             f\"# District Cleaning â€” {state}\\n\\n\"\n",
    "#             \"This notebook standardizes **district names** for this state across:\\n\"\n",
    "#             \"- Enrolment data\\n\"\n",
    "#             \"- Demographic update data\\n\"\n",
    "#             \"- Biometric update data\\n\\n\"\n",
    "#             \"**All data is saved back to the same cleaned files.**\"\n",
    "#         ),\n",
    "#\n",
    "#         # ----------------------------\n",
    "#         # Load datasets\n",
    "#         # ----------------------------\n",
    "#         new_code_cell(\n",
    "#             \"\"\"import pandas as pd\n",
    "# from pathlib import Path\n",
    "#\n",
    "# pd.set_option(\"display.max_rows\", None)\n",
    "# pd.set_option(\"display.width\", None)\n",
    "#\n",
    "# CLEAN_DIR = Path(\"../../data/processed/cleaned\")\n",
    "#\n",
    "# enrol_df = pd.read_csv(CLEAN_DIR / \"enrolment_clean.csv\")\n",
    "# demo_df  = pd.read_csv(CLEAN_DIR / \"demographic_clean.csv\")\n",
    "# bio_df   = pd.read_csv(CLEAN_DIR / \"biometric_clean.csv\")\n",
    "#\n",
    "# for df in [enrol_df, demo_df, bio_df]:\n",
    "#     df[\"state\"] = df[\"state\"].astype(str).str.strip().str.title()\n",
    "#     df[\"district\"] = df[\"district\"].astype(str).str.strip().str.title()\n",
    "#\n",
    "# print(\"âœ… All datasets loaded and normalized (Title Case)\")\n",
    "# \"\"\"\n",
    "#         ),\n",
    "#\n",
    "#         # ----------------------------\n",
    "#         # Print districts (FULL HEIGHT)\n",
    "#         # ----------------------------\n",
    "#         new_code_cell(\n",
    "#             f\"\"\"STATE_NAME = \"{state}\"\n",
    "#\n",
    "# districts = sorted(\n",
    "#     set(\n",
    "#         enrol_df.loc[enrol_df[\"state\"] == STATE_NAME, \"district\"].dropna()\n",
    "#         .tolist()\n",
    "#     )\n",
    "# )\n",
    "#\n",
    "# print(f\"State: {{STATE_NAME}}\")\n",
    "# print(f\"Number of unique districts: {{len(districts)}}\")\n",
    "#\n",
    "# pd.DataFrame(\n",
    "#     {{\"District Name\": districts}}\n",
    "# )\n",
    "# \"\"\"\n",
    "#         ),\n",
    "#\n",
    "#         # ----------------------------\n",
    "#         # Mapping instructions\n",
    "#         # ----------------------------\n",
    "#         new_markdown_cell(\n",
    "#             \"## District Mapping\\n\\n\"\n",
    "#             \"Add mappings in **Title Case only**.\\n\\n\"\n",
    "#             \"Format:\\n\"\n",
    "#             \"```python\\n\"\n",
    "#             \"DISTRICT_MAPPING = {\\n\"\n",
    "#             \"    \\\"Correct District\\\": [\\\"Wrong Name 1\\\", \\\"Wrong Name 2\\\"],\\n\"\n",
    "#             \"}\\n\"\n",
    "#             \"```\"\n",
    "#         ),\n",
    "#\n",
    "#         # ----------------------------\n",
    "#         # Apply mapping (SAFE for all datasets)\n",
    "#         # ----------------------------\n",
    "#         new_code_cell(\n",
    "#             f\"\"\"DISTRICT_MAPPING = {{\n",
    "#     # \"Correct District\": [\"Wrong Variant 1\", \"Wrong Variant 2\"]\n",
    "# }}\n",
    "#\n",
    "# def apply_mapping(df, state, mapping, label):\n",
    "#     total = 0\n",
    "#     for correct, wrongs in mapping.items():\n",
    "#         mask = (\n",
    "#             (df[\"state\"] == state) &\n",
    "#             (df[\"district\"].isin(wrongs))\n",
    "#         )\n",
    "#         count = mask.sum()\n",
    "#         df.loc[mask, \"district\"] = correct\n",
    "#         total += count\n",
    "#         if count > 0:\n",
    "#             print(f\"âœ” {{label}} â†’ {{correct}} : {{count}} rows fixed\")\n",
    "#     return total\n",
    "#\n",
    "# total_fixes = 0\n",
    "# total_fixes += apply_mapping(enrol_df, STATE_NAME, DISTRICT_MAPPING, \"Enrolment\")\n",
    "# total_fixes += apply_mapping(demo_df,  STATE_NAME, DISTRICT_MAPPING, \"Demographic\")\n",
    "# total_fixes += apply_mapping(bio_df,   STATE_NAME, DISTRICT_MAPPING, \"Biometric\")\n",
    "#\n",
    "# print(f\"âœ… Total fixes in {{STATE_NAME}}: {{total_fixes}}\")\n",
    "# \"\"\"\n",
    "#         ),\n",
    "#\n",
    "#         # ----------------------------\n",
    "#         # Save back to SAME files\n",
    "#         # ----------------------------\n",
    "#         new_code_cell(\n",
    "#             \"\"\"enrol_df.to_csv(CLEAN_DIR / \"enrolment_clean.csv\", index=False)\n",
    "# demo_df.to_csv(CLEAN_DIR / \"demographic_clean.csv\", index=False)\n",
    "# bio_df.to_csv(CLEAN_DIR / \"biometric_clean.csv\", index=False)\n",
    "#\n",
    "# print(\"ðŸ’¾ All cleaned files saved successfully (overwritten)\")\n",
    "# \"\"\"\n",
    "#         )\n",
    "#     ])\n",
    "#\n",
    "#     with open(nb_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#         nbformat.write(nb, f)\n",
    "#\n",
    "#     print(f\"âœ” Created: {nb_path}\")\n",
    "#\n",
    "# print(\"ðŸŽ‰ All state-wise district cleaning notebooks generated successfully.\")\n"
   ],
   "id": "77318d5f2ff50c67",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
