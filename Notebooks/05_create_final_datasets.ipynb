{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6ebebd70c73689d",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "## (Make sure to run all the state_wise cleaning files before this)\n",
    "Prepare analysis-ready datasets from cleaned Aadhaar data.\n",
    "Input: data/processed/cleaned/\n",
    "Output: data/processed/analysis/\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "bcaf8fc8b8f6682c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T16:51:59.400851Z",
     "start_time": "2026-01-16T16:51:59.013087Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_PATH = Path(\"..\") / \"data\" / \"processed\"\n",
    "CLEAN_PATH = BASE_PATH / \"cleaned\"\n",
    "ANALYSIS_PATH = BASE_PATH / \"analysis\"\n",
    "\n",
    "ANALYSIS_PATH.mkdir(parents=True, exist_ok=True)\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "7595ac94b59a2394",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T16:52:01.206067Z",
     "start_time": "2026-01-16T16:51:59.407210Z"
    }
   },
   "source": [
    "# Enrolment → enrolment_analysis.csv\n",
    "\n",
    "enrol = pd.read_csv(CLEAN_PATH / \"enrolment_clean.csv\")\n",
    "\n",
    "# unified age buckets (SAFE RULE)\n",
    "enrol[\"child_count\"] = enrol[\"age_0_5\"]\n",
    "enrol[\"non_child_count\"] = enrol[\"age_5_17\"] + enrol[\"age_17_plus\"]\n",
    "\n",
    "enrol[\"total_enrolment\"] = enrol[\"child_count\"] + enrol[\"non_child_count\"]\n",
    "\n",
    "enrolment_analysis = enrol[\n",
    "    [\n",
    "        \"date\", \"state\", \"district\", \"pincode\",\n",
    "        \"child_count\", \"non_child_count\", \"total_enrolment\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "enrolment_analysis.to_csv(\n",
    "    ANALYSIS_PATH / \"enrolment_analysis.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"✅ enrolment_analysis.csv created\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ enrolment_analysis.csv created\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "74cf0bef2f40b1ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T16:52:01.213769Z",
     "start_time": "2026-01-16T16:52:01.211492Z"
    }
   },
   "source": [
    "print(enrol.columns.tolist())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'state', 'district', 'pincode', 'age_0_5', 'age_5_17', 'age_17_plus', 'state_clean', 'district_clean', 'child_count', 'non_child_count', 'total_enrolment']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "b3680299c9edfefd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T16:52:10.935410Z",
     "start_time": "2026-01-16T16:52:01.237462Z"
    }
   },
   "source": [
    "# ================================\n",
    "# Updates Analysis Dataset Creation\n",
    "# ================================\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load cleaned datasets\n",
    "demo = pd.read_csv(CLEAN_PATH / \"demographic_clean.csv\")\n",
    "bio = pd.read_csv(CLEAN_PATH / \"biometric_clean.csv\")\n",
    "\n",
    "# Explicitly set update_type (overwrite if exists)\n",
    "demo[\"update_type\"] = \"demographic\"\n",
    "bio[\"update_type\"] = \"biometric\"\n",
    "\n",
    "# Merge both updates\n",
    "updates = pd.concat([demo, bio], ignore_index=True)\n",
    "\n",
    "# ----------------\n",
    "# Normalize geography fields\n",
    "# ----------------\n",
    "for col in [\"state\", \"district\", \"pincode\"]:\n",
    "    updates[col] = (\n",
    "        updates[col]\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .str.title()\n",
    "    )\n",
    "# ----------------\n",
    "# Compute total updates\n",
    "# (no 0–5 age group exists for updates)\n",
    "# ----------------\n",
    "updates[\"total_updates\"] = updates.filter(like=\"_age_\").sum(axis=1)\n",
    "\n",
    "# ----------------\n",
    "# Final analysis dataframe\n",
    "# ----------------\n",
    "updates_analysis = updates[\n",
    "    [\n",
    "        \"date\",\n",
    "        \"state\",\n",
    "        \"district\",\n",
    "        \"pincode\",\n",
    "        \"update_type\",\n",
    "        \"total_updates\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "# ----------------\n",
    "# Save final analysis file\n",
    "# ----------------\n",
    "updates_analysis.to_csv(\n",
    "    ANALYSIS_PATH / \"updates_analysis.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"✅ updates_analysis.csv created with BOTH demographic and biometric updates\")\n",
    "print(updates_analysis[\"update_type\"].value_counts())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ updates_analysis.csv created with BOTH demographic and biometric updates\n",
      "update_type\n",
      "biometric      1766159\n",
      "demographic    1598010\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
